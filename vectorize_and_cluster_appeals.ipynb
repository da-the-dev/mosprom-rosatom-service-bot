{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Кластеризация обращений с использованием векторных представлений\n",
        "\n",
        "Этот notebook выполняет анализ обращений с помощью:\n",
        "- Векторизации текста через Yandex Embeddings API\n",
        "- Кластеризации методом K-means\n",
        "- Анализа результатов кластеризации\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Импорт библиотек и настройка\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas numpy scikit-learn pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "from collections import Counter\n",
        "import warnings\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Проверяем аргументы командной строки\n",
        "FORCE_RECACHE = '--recache' in sys.argv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Настройка параметров API\n",
        "\n",
        "**ВНИМАНИЕ:** Замените значения ниже на ваши реальные данные для работы с Yandex Cloud API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Настройки ===\n",
        "APPEALS_FILE = \"Обращения.txt\"\n",
        "VECTORS_CACHE_FILE = \"appeals_vectors_cache.pkl\"\n",
        "\n",
        "# ЗАМЕНИТЕ НА ВАШИ ДАННЫЕ:\n",
        "YANDEX_FOLDER_ID = \"YOUR_FOLDER_ID_HERE\"\n",
        "IAM_TOKEN = \"YOUR_IAM_TOKEN_HERE\"\n",
        "\n",
        "EMBEDDING_URL = \"https://llm.api.cloud.yandex.net/foundationModels/v1/textEmbedding\"\n",
        "MODEL_URI = f\"emb://{YANDEX_FOLDER_ID}/text-search-query/latest\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Функция для получения эмбеддинга\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_embedding(text: str) -> list[float]:\n",
        "    \"\"\"Получение вектора через Yandex Embeddings API\"\"\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {IAM_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"modelUri\": MODEL_URI,\n",
        "        \"text\": text\n",
        "    }\n",
        "    try:\n",
        "        response = requests.post(EMBEDDING_URL, json=payload, headers=headers)\n",
        "        if response.status_code != 200:\n",
        "            raise Exception(f\"Ошибка Yandex API: {response.status_code} - {response.text}\")\n",
        "        return response.json()[\"embedding\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при получении эмбеддинга для текста: {text[:50]}...\")\n",
        "        print(f\"Детали ошибки: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка обращений\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Загружаем обращения...\")\n",
        "with open(APPEALS_FILE, 'r', encoding='utf-8') as f:\n",
        "    appeals = [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "print(f\"Найдено {len(appeals)} обращений\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Векторизация обращений\n",
        "\n",
        "Этот этап может занять значительное время в зависимости от количества обращений. Используется кэширование для ускорения повторных запусков.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Проверка кэша векторов ===\n",
        "if os.path.exists(VECTORS_CACHE_FILE) and not FORCE_RECACHE:\n",
        "    print(\"Найден кэш векторов, загружаем...\")\n",
        "    with open(VECTORS_CACHE_FILE, 'rb') as f:\n",
        "        cache_data = pickle.load(f)\n",
        "        vectors = cache_data['vectors']\n",
        "        successful_appeals = cache_data['appeals']\n",
        "    print(f\"Загружено {len(vectors)} векторов из кэша\")\n",
        "else:\n",
        "    if FORCE_RECACHE:\n",
        "        print(\"Принудительное обновление кэша...\")\n",
        "    else:\n",
        "        print(\"Кэш не найден, начинаем векторизацию обращений...\")\n",
        "    vectors = []\n",
        "    successful_appeals = []\n",
        "\n",
        "    for idx, appeal in enumerate(appeals, 1):\n",
        "        print(f\"Обработка {idx}/{len(appeals)}: {appeal[:50]}...\")\n",
        "        \n",
        "        embedding = get_embedding(appeal)\n",
        "        if embedding is not None:\n",
        "            vectors.append(embedding)\n",
        "            successful_appeals.append(appeal)\n",
        "        else:\n",
        "            print(f\"Пропущено обращение {idx}\")\n",
        "        \n",
        "        time.sleep(0.1)  # Избегаем лимитов API\n",
        "\n",
        "    print(f\"Успешно векторизовано {len(vectors)} обращений\")\n",
        "    \n",
        "    # Сохраняем кэш\n",
        "    print(\"Сохраняем векторы в кэш...\")\n",
        "    cache_data = {\n",
        "        'vectors': vectors,\n",
        "        'appeals': successful_appeals\n",
        "    }\n",
        "    with open(VECTORS_CACHE_FILE, 'wb') as f:\n",
        "        pickle.dump(cache_data, f)\n",
        "    print(\"Кэш сохранен!\")\n",
        "\n",
        "if len(vectors) == 0:\n",
        "    print(\"Ошибка: не удалось получить ни одного вектора\")\n",
        "    raise Exception(\"Нет векторов для анализа\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Подготовка данных для кластеризации\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Подготовка данных ===\n",
        "vectors_array = np.array(vectors)\n",
        "print(f\"Размер матрицы векторов: {vectors_array.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Кластеризация методом K-means\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Кластеризация ===\n",
        "optimal_k = 20  # Фиксированное количество кластеров\n",
        "print(f\"Выполняем кластеризацию с k={optimal_k}...\")\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(vectors_array)\n",
        "\n",
        "# Вычисляем silhouette score для оценки качества кластеризации\n",
        "silhouette_avg = silhouette_score(vectors_array, cluster_labels)\n",
        "print(f\"Silhouette score для {optimal_k} кластеров: {silhouette_avg:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Создание DataFrame для анализа\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Создание DataFrame для анализа ===\n",
        "df_results = pd.DataFrame({\n",
        "    'appeal': successful_appeals,\n",
        "    'cluster': cluster_labels\n",
        "})\n",
        "\n",
        "print(f\"DataFrame создан с {len(df_results)} записями\")\n",
        "df_results.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Статистика по кластерам\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Статистика по кластерам ===\n",
        "print(\"=== СТАТИСТИКА ПО КЛАСТЕРАМ ===\")\n",
        "cluster_stats = df_results.groupby('cluster').agg({\n",
        "    'appeal': 'count'\n",
        "}).rename(columns={'appeal': 'count'})\n",
        "\n",
        "cluster_stats['percentage'] = (cluster_stats['count'] / len(df_results) * 100).round(2)\n",
        "print(cluster_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Примеры обращений по кластерам\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Примеры обращений по кластерам ===\n",
        "print(\"=== ПРИМЕРЫ ОБРАЩЕНИЙ ПО КЛАСТЕРАМ ===\")\n",
        "for cluster_id in sorted(df_results['cluster'].unique()):\n",
        "    cluster_appeals = df_results[df_results['cluster'] == cluster_id]['appeal'].tolist()\n",
        "    print(f\"\\nКластер {cluster_id} ({len(cluster_appeals)} обращений):\")\n",
        "    for i, appeal in enumerate(cluster_appeals[:3]):  # Показываем первые 3\n",
        "        print(f\"  {i+1}. {appeal[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Дополнительная статистика\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Дополнительная статистика ===\n",
        "print(\"=== ДОПОЛНИТЕЛЬНАЯ СТАТИСТИКА ===\")\n",
        "print(f\"Общее количество обращений: {len(successful_appeals)}\")\n",
        "print(f\"Количество кластеров: {optimal_k} (фиксированное)\")\n",
        "print(f\"Средний размер кластера: {len(successful_appeals)/optimal_k:.1f}\")\n",
        "print(f\"Максимальный размер кластера: {cluster_counts.max()}\")\n",
        "print(f\"Минимальный размер кластера: {cluster_counts.min()}\")\n",
        "print(f\"Silhouette score: {silhouette_avg:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Сохранение результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Сохранение результатов ===\n",
        "print(\"Сохраняем результаты...\")\n",
        "df_results.to_csv('appeals_clustering_results.csv', index=False, encoding='utf-8')\n",
        "cluster_stats.to_csv('cluster_statistics.csv', encoding='utf-8')\n",
        "\n",
        "print(\"✅ Анализ завершен!\")\n",
        "print(\"Файлы созданы:\")\n",
        "print(\"- appeals_clustering_results.csv - детальные результаты\")\n",
        "print(\"- cluster_statistics.csv - статистика по кластерам\")\n",
        "print(\"- appeals_vectors_cache.pkl - кэш векторов (для быстрого перезапуска)\")\n",
        "print(\"\\nДля принудительного обновления кэша используйте: python vectorize_and_cluster_appeals.py --recache\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Заключение\n",
        "\n",
        "Этот notebook выполняет анализ обращений с помощью векторных представлений:\n",
        "\n",
        "1. **Векторизация**: Преобразование текстовых обращений в числовые векторы через Yandex Embeddings API\n",
        "2. **Кластеризация**: Группировка обращений в тематические кластеры с помощью K-means\n",
        "3. **Анализ**: Статистический анализ результатов кластеризации\n",
        "\n",
        "### Основные результаты:\n",
        "- Кластеры группируют схожие по тематике обращения\n",
        "- Silhouette score показывает качество кластеризации\n",
        "- Статистика помогает понять распределение данных по кластерам\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
